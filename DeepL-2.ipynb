{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esperimento 2 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Esperimento:** Creare un Convolutional Autoencoder per allenare un Neural Network sul dataset KMnist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le variabili e le funzioni di base e importiamo le librerie richieste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive             # Nel caso si voglia eseguire il codice su Google Colab, togliere i commenti a questi import.\n",
    "import numpy as np\n",
    "import torch\n",
    "from dadapy import data\n",
    "from torchvision.datasets import KMNIST\n",
    "from torchvision.transforms import ToTensor as tvToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#drive.mount('/content/drive')\n",
    "#%cd drive/MyDrive/DeepLearning2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096               # E' possibile ridurre la batch_size nel caso il device non sia capace di sostenere il load.\n",
    "training_rate = 0.002\n",
    "momentum = 0.98\n",
    "gamma = 0.9995\n",
    "dropout = 0.2\n",
    "weight_decay = 0.0\n",
    "alpha = 0.33\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(input, output):\n",
    "    if input is not None:\n",
    "        plt.figure(figsize=(18, 4))\n",
    "        for i in range(4):\n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.imshow(input[i].reshape(28,28), cmap=\"gray\")    \n",
    "    plt.figure(figsize=(18, 4))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(output[i].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della dimensione intrinseca del dataset kMNIST tramite <a href=\"https://www.nature.com/articles/s41598-017-11873-y\">TwoNN</a>, utilizzando il <a href=\"https://dadapy.readthedocs.io/en/latest/jupyter_example_3.html\">dadapy package</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_decimation = 1.0\n",
    "\n",
    "trainset = KMNIST(root='./data', train=True, download=True, transform=tvToTensor())\n",
    "testset = KMNIST(root='./data', train=False, download=True, transform=tvToTensor())\n",
    "\n",
    "nptrainset = trainset.data.numpy().reshape(-1,28*28) # Trasforma le immagini in 2D in liste. La shape è (60000,784).\n",
    "_data = data.Data(nptrainset)\n",
    "id_twoNN, _, r = _data.compute_id_2NN(fraction=0.9,decimation=_decimation) # Calcola la dimensione intrinseca del dataset kMNIST (dovrebbe avere un valore attorno a 20). Potrebbe richiedere del tempo per essere calcolata, ridurre la decimation velocizza il processo.\n",
    "print(int(id_twoNN)+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a definire l'autoencoder che utilizzeremo per ridurre la dimensionalità di KMNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = int(id_twoNN)+1\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ELU(alpha=alpha),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Dropout(p=dropout),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.ELU(alpha=alpha),\n",
    "            torch.nn.MaxPool2d(kernel_size=2,stride=1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(6*6*64, d)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d, 64*8*8),\n",
    "            torch.nn.ELU(alpha=alpha),\n",
    "            torch.nn.Unflatten(1, torch.Size([64, 8, 8])),\n",
    "            torch.nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.ELU(alpha=alpha),\n",
    "            torch.nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=2, stride=2, padding=0),\n",
    "        )    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "\n",
    "autoencoder = AE().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo l'optimizer e la funzione loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer_ae = torch.optim.Adam(autoencoder.parameters(), lr=training_rate)\n",
    "loss_ae = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleniamo il nostro autoencoder sul dataset KMNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50    # 300 epochs sono il limite per il miglioramento del loss.\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    autoencoder.train()\n",
    "    train_loss = 0\n",
    "    for x,y in iter(trainloader):\n",
    "        x=x.to(device)\n",
    "        x_hat=autoencoder(x)\n",
    "        l=loss_ae(x_hat,x)\n",
    "        train_loss+=l.item()\n",
    "        optimizer_ae.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer_ae.step()\n",
    "        \n",
    "    print(\"Epoch \"+str(epoch+1)+\" Training loss:\"+str(train_loss / (len(trainloader.dataset))))\n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    test_loss=0 \n",
    "    for x,y in iter(testloader):\n",
    "            x=x.to(device)\n",
    "            x_hat=autoencoder(x)\n",
    "            l=loss_ae(x_hat,x)\n",
    "            test_loss+=l.item()\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print(\"Test set loss:\"+str(test_loss))\n",
    "    display_images(x.cpu(), x_hat.cpu())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo un classificatore lineare che fa uso dell'encoder come \"metodo di compressione\" per il nostro dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features=d, out_features=16, bias=True)\n",
    "        self.layer2 = torch.nn.Linear(in_features=16,out_features=10, bias=True)\n",
    "        self.activation = torch.nn.ELU(alpha=alpha)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.activation(self.layer1(x))\n",
    "        x=self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classifier = LinearClassifier().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo l'optimizer, lo scheduler e la funzione loss del classificatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cl = torch.optim.SGD(classifier.parameters(), lr=training_rate, momentum=momentum)\n",
    "scheduler_cl = torch.optim.lr_scheduler.ExponentialLR(optimizer_cl, gamma=gamma)\n",
    "loss_cl = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le funzioni per aggiustare il dataset all'architettura (in particolare una funzione per modificare i labels da numeri ad array selettori) e la funzione per l'accuratezza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def selector(y):\n",
    "    out = torch.zeros([y.size(dim=0), 10], dtype=torch.float32)\n",
    "    for idx,k in enumerate(y):\n",
    "        out[idx][k] = 1.0\n",
    "    out = out.to(device)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        for x, y in iter(dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=autoencoder.encoder(x)\n",
    "            out=model(x)\n",
    "            correct+=(torch.argmax(out, axis=1)==y).sum()\n",
    "        return (correct/len(dataloader.dataset)).item()\n",
    "\n",
    "print(selector(torch.tensor([6])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleniamo il classifier sul dataset (compresso):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500\n",
    "\n",
    "losses=[]\n",
    "for epoch in range(epochs):\n",
    "    print(\"Test accuracy: \", get_accuracy(classifier, testloader))\n",
    "    classifier.train()\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for x, y in iter(trainloader):\n",
    "        x = x.to(device)\n",
    "        x = autoencoder.encoder(x)\n",
    "        y = y.unsqueeze(1)\n",
    "        y = selector(y)\n",
    "        out=classifier(x)\n",
    "        l=loss_cl(out, y)\n",
    "        optimizer_cl.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer_cl.step()\n",
    "        losses.append(l.item())\n",
    "    scheduler_cl.step()\n",
    "print(\"Final accuracy: \", get_accuracy(classifier, testloader))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMNIST batch loss\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Optimization step\")\n",
    "plt.ylabel(\"MSE Loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusioni"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'autoencoder riesce a comprimere il dataset kMNIST nelle d features calcolate allo Step 1 e un classificatore è capace di catalogare le immagini in base a queste features.<br>\n",
    "Con 300 epochs sull'autoencoder e 40 epochs sul classificatore è possibile raggiungere un'accuratezza del ~75% in maniera consistente, un risultato decisamente migliore rispetto alla selezione casuale (~10% di accuratezza)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e611b0851ec25071b4b85132416ea565c11a628bf418623b3546e687a0b7c369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
