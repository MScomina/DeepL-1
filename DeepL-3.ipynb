{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esperimento 3 - Deep Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Esperimento:** Completare <a href=\"https://www.cs.toronto.edu/~hinton/FFA13.pdf\">il nuovo algoritmo Forward-Forward</a>, presentato alla conferenza NeurIPS 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "p_goodness = 3                              # Esponente della somma utilizzata nella funzione di goodness. E.g.: 1 indica la somma semplice, 2 indica la somma di quadrati etc.\n",
    "p_norm = 1.5                                # Norma di grado p. https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm\n",
    "epochs = 600\n",
    "batches = 2                                 # Numero di batches per evitare di esaurire la memoria, impostare a 1 per full batch training. La accuracy sull'insieme di training è solo su una batch.\n",
    "function = torch.nn.SiLU()                  # Funzione di attivazione utilizzata nell'architettura.\n",
    "neurons = [784,60,60]                       # Neuroni dell'architettura\n",
    "\n",
    "#from google.colab import drive             # Nel caso si voglia eseguire il codice su Google Colab, togliere i commenti a questi import.\n",
    "#drive.mount('/content/drive')\n",
    "#%cd drive/MyDrive/DeepLearning2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una goodness function da utilizzare e la funzione per fare l'embedding dei label nell'input:<br>\n",
    "References: https://github.com/mohammadpz/pytorch_forward_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_function(x:torch.Tensor, p:int=p_goodness):\n",
    "    goodness = x.pow(p).mean(1)\n",
    "    return goodness\n",
    "    \n",
    "def label_images(images, labels):\n",
    "    #Embedding del label nelle immagini.\n",
    "    x_ = images.clone()\n",
    "    x_[:, :10] *= 0.0\n",
    "    x_[range(images.shape[0]), labels] = images.max()\n",
    "    return x_\n",
    "\n",
    "def normalize(x:torch.Tensor, p:float=p_norm):\n",
    "    #Normalizzazione p per layer.\n",
    "    return x / (x.norm(p, 1, keepdim=True) + 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "        self.relu = function\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = epochs*batches\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_direction = normalize(x)\n",
    "        return self.relu(self.linear(x_direction))\n",
    "\n",
    "    def train(self, x_pos, x_neg):\n",
    "        for i in range(self.num_epochs):\n",
    "            positive_goodness = goodness_function(self.forward(x_pos))\n",
    "            negative_goodness = goodness_function(self.forward(x_neg))\n",
    "            l = torch.log(1 + torch.exp(torch.cat([\n",
    "                -positive_goodness + self.threshold,\n",
    "                negative_goodness - self.threshold]))).mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            self.optimizer.step()\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dimensions):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList([ReLULayer(dimensions[i], dimensions[i + 1]) for i in range(len(dimensions)-1)])\n",
    "    def predict(self, x):\n",
    "        goodness_per_label = []\n",
    "        for label in range(10):\n",
    "            x_lab = label_images(x, label)\n",
    "            goodness = []\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                x_lab = layer(x_lab)\n",
    "                if i>0:\n",
    "                    goodness.append(\n",
    "                        goodness_function(x_lab)\n",
    "                    )\n",
    "            goodness_per_label.append(sum(goodness).unsqueeze(1))\n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "        return torch.argmax(goodness_per_label, dim=1)\n",
    "    \n",
    "    def train(self, x_pos, x_neg):\n",
    "        for layer in self.layers:\n",
    "            x_pos, x_neg = layer.train(x_pos, x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,)), torchvision.transforms.Lambda(torch.flatten)])\n",
    "\n",
    "trainset = torchvision.datasets.KMNIST('./data/', transform=transform,  train=True, download=True)                  # La maggior parte dei test sono stati eseguiti sul dataset KMNIST, in quanto più difficile da imparare di MNIST.\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=(int(60000/batches)), shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.KMNIST('./data/', transform=transform, train=False, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8967999815940857\n",
      "Test accuracy: 0.7622999548912048\n"
     ]
    }
   ],
   "source": [
    "net = Net(neurons).to(device)\n",
    "x, y = next(iter(trainloader))\n",
    "x=x.to(device)\n",
    "y=y.to(device)\n",
    "x_pos = label_images(x, y)\n",
    "rnd = torch.randperm(x.size(0))\n",
    "\n",
    "x_neg = label_images(x, y[rnd])\n",
    "net.train(x_pos, x_neg)\n",
    "\n",
    "print('Train accuracy:', net.predict(x).eq(y).float().mean().item())\n",
    "\n",
    "x_te, y_te = next(iter(testloader))\n",
    "x_te=x_te.to(device)\n",
    "y_te=y_te.to(device)\n",
    "\n",
    "print('Test accuracy:', net.predict(x_te).eq(y_te).float().mean().item())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Analisi delle funzioni di attivazione: \"What is the best activation function to use?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sono state esaminate varie funzioni di attivazione inizializzate con vari iperparametri diversi, e sono emersi i seguenti risultati sui dataset MNIST/KMNIST:\n",
    "- La funzione ReLU è la funzione che offre le performance migliori, ed è la più portata per questi dataset.\n",
    "- Le funzioni limitate come sigmoid e tanh tendono a non performare bene a causa del valore di threshold.\n",
    "- Altre funzioni illimitate che posseggono parte negativa come SiLU o ELU posseggono maggiore capacità di esplorazione, in quanto non sono limitate all'ortante positivo, ma tendono a performare peggio rispetto a ReLU con lo scalare della dimensione dell'architettura.\n",
    "\n",
    "Per quanto riguarda la normalizzazione, è stato osservato che altri tipi di norme sono capaci di performare alla pari, o meglio, della norma 2. Un esempio è la norma 1.8, che porta a un miglioramento sull'insieme di test medio del ~3% sul dataset KMNIST.\n",
    "È quindi valido supporre l'esistenza di norme e/o di funzioni di attivazione migliori capaci di raggiungere una performance migliore con l'algoritmo Forward-Forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Analisi della funzione di goodness: \"What is the best goodness function to use?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminando la funzione di goodness, è stata valutata la possibilità di avere somme di valori non strettamente positivi quali somma di cubi e somma semplice.<br>\n",
    "Questo, teoricamente, consentirebbe alla funzione di goodness di avere valori negativi (per funzioni di attivazione diverse da ReLU), influenzando il valore di goodness negativo e consentendo all'architettura di aumentare l'esplorazione.<br>\n",
    "È stato osservato che il valore ottimale di norma dipende dal tipo di somma effettuato (generalmente in maniera inversamente proporzionale rispetto al grado), e che la somma di cubi è un'ottima funzione di goodness per quanto riguarda le funzioni illimitate con valori negativi (e.g. SiLU), con un'accuracy media che raggiunge l'80% sull'insieme di test per quanto riguarda il dataset KMNIST per l'architettura considerata, superando persino la classica somma di quadrati con la funzione ReLU.<br>\n",
    "Per quanto riguarda la somma semplice sono stati ottenuti risultati accettabili (~65% accuratezza sull'insieme di test) ma non al livello della classica funzione di goodness di somma di quadrati.\n",
    "\n",
    "È necessario evidenziare come l'architettura presentata (784,500,500) sia decisamente esagerata e tenda decisamente all'overfitting. Un'architettura molto più piccola (784,60,60), fermata al numero adeguato di epochs, è capace di performare quasi alla pari dell'architettura presentata (~76% invece di ~80%) e presenta ancora segni di overfitting. È quindi evidente che è possibile espandere e studiare ulteriormente quest'architettura per raggiungere risultati ancora più soddisfacenti."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e611b0851ec25071b4b85132416ea565c11a628bf418623b3546e687a0b7c369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
